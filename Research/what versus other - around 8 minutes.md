Steganography hides the message, not the meaning of the message. 
• Compare with alternatives?

Talk about one versus the other, but also how they could compliment each other.

- cryptography: hiding the meaning of the message 1 + 1 min
- obfuscation: hides/alters data/ code 1 min
- watermarking: embeds identifiable data into media 1 min

AI is poisoning data: 1.30 min
- 'One of the most concerning emerging risks in AI governance is steganography' - AI concealing information 
- https://verityai.co/blog/ai-steganography-hidden-communication-risks

AI gets poisoned data: 1.30 min
- 'but what if that training data is deliberately poisoned'
- For example, an image of a dog might be poisoned with a data label that describes it as a lampshade or a cat.
- but one illustration would be to hide a prompt within a text file by making it white text on a white background.
- https://www.informationdifference.com/hiding-in-plain-sight-ai-data-poisoning/
- AI systems are more interconnected and data-driven than ever, making them ripe targets for steganographic attacks
- Evasion attacks – altering an input to trick the AI post-deployment
- Poisoning attacks – corrupting data at the training stage
- Prompt injection – text prompts designed to enable the user to perform unintended or unauthorized actions
- Privacy attacks – extracting or reconstructing sensitive information from training or input data
- https://owlcyberdefense.com/blog/hidden-threats-in-ai-data-protecting-against-steganography/